{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "import Config as config\n",
    "import findspark\n",
    "from pyspark.sql import types as typ\n",
    "import pyspark.sql.functions as F\n",
    "import nltk,string\n",
    "from nltk import word_tokenize,SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import pyspark.ml.feature  as feat\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "findspark.init(\"/usr/local/spark/spark-2.2.0-bin-hadoop2.7\")\n",
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-8_2.11:2.2.0,org.apache.spark:spark-sql-kafka-0-10_2.11:2.2.0 pyspark-shell'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"real-time\").getOrCreate()\n",
    "\n",
    "@F.udf(typ.StringType())\n",
    "def process_text(text):    \n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/french.pickle')\n",
    "    stemmer_snowball = SnowballStemmer('french')\n",
    "    stopword = set(stopwords.words('french'))\n",
    "    sentence = tokenizer.tokenize(text)\n",
    "    sentence = \" \".join([sent.lower() for sent in sentence])\n",
    "    clean_words = [word for word in nltk.word_tokenize(sentence) if word not in stopword.union(string.punctuation)]\n",
    "    clean_words = [stemmer_snowball.stem(lem) for lem in clean_words]\n",
    "    clean_words = \" \".join(clean_words)\n",
    "    return clean_words\n",
    "\n",
    "def vectorizer(df):\n",
    "    df = df.select('sentences',\"polarity\").withColumn(\"wordSentences\",process_text(\"sentences\"))\\\n",
    "    .withColumn(\"label\", F.col(\"polarity\").cast(typ.DoubleType()))\n",
    "    df = df.select(\"sentences\",\"wordSentences\",\"label\").withColumn(\"words\",F.split(F.col(\"wordSentences\"),' '))\n",
    "    df = df.select(\"sentences\",\"words\",\"label\")\n",
    "    tf = feat.HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\")\n",
    "    idf = feat.IDF(inputCol=\"rawFeatures\",outputCol=\"features\")\n",
    "    pipelineTFIDF = Pipeline(stages=[tf,idf])\n",
    "    pipelineFit = pipelineTFIDF.fit(df)\n",
    "    df = pipelineFit.transform(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    df = x.toDF(['sentences','polarity'])\n",
    "    df = vectorizer(df)\n",
    "    logregModel = LogisticRegressionModel.load(\"model_nlp\")\n",
    "    pred = logregModel.transform(df)\n",
    "    pred = pred.select(\"sentences\",\"prediction\")\n",
    "    pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc = StreamingContext(spark.sparkContext,1)\n",
    "stream = KafkaUtils.createDirectStream(ssc, [config.kafka_topic_name], {'metadata.broker.list':config.bootstrap_servers})\n",
    "lines = stream.map(lambda x: x[1])\n",
    "lines.map(lambda x: x.split('\\t')).foreachRDD(func)\n",
    "ssc.start()\n",
    "#ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
